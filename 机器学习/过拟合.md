过拟合（over-fitting），机器学习模型或者是深度学习模型在训练样本中表现得过于优越，导致在验证数据集以及测试数据集中表现不佳。出现这种现象的主要原因是训练数据中存在噪音或者训练数据太少。

过拟合问题，根本的原因则是特征维度(或参数)过多，导致拟合的函数完美的经过训练集，但是对新数据的预测结果则较差。

常见原因

**1）建模样本选取有误，如样本数量太少，选样方法错误，样本标签错误等，导致选取的样本数据不足以代表预定的分类规则；**

**2）样本噪音干扰过大，使得机器将部分噪音认为是特征从而扰乱了预设的分类规则；**

**3）假设的模型无法合理存在，或者说是假设成立的条件实际并不成立；**

**4）参数太多，模型复杂度过高；**

**5）对于决策树模型，如果我们对于其生长没有合理的限制，其自由生长有可能使节点只包含单纯的事件数据(event)或非事件数据(no event)，使其虽然可以完美匹配（拟合）训练数据，但是无法适应其他数据集。**

6）对于神经网络模型：

a)对样本数据可能存在分类决策面不唯一，随着学习的进行,，BP算法使权值可能收敛过于复杂的决策面；

b)权值学习迭代次数足够多(Overtraining)，拟合了训练数据中的噪声和训练样例中没有代表性的特征。

解决方法

**1）在神经网络模型中，可使用权值衰减的方法，即每次迭代过程中以某个小因子降低每个权值。**

**2）选取合适的停止训练标准，使对机器的训练在合适的程度；**

**3）保留验证数据集，对训练成果进行验证；**

**4）获取额外数据进行交叉验证；**

**5）正则化，即在进行目标函数或代价函数优化时，在目标函数或代价函数。**

以下摘抄自csdn-Fitz博客:

造成过拟合的原因有可以归结为：参数过多或样本过少。那么我们需要做的事情就是减少参数，提供两种办法：

1、回想下我们的模型，假如我们采用梯度下降算法将模型中的损失函数不断减少，那么最终我们会在一定范围内求出最优解，最后损失函数不断趋近0。那么我们可以在所定义的损失函数后面加入一项永不为0的部分，那么最后经过不断优化损失函数还是会存在。其实这就是所谓的“正则化”。

一个通俗的理解便是：更小的参数值w意味着模型的复杂度更低，对训练数据的拟合刚刚好（奥卡姆剃刀）。

下面这张图片就是加入了正则化（regulation）之后的损失函数。这里m是样本数目，表示的是正则化系数。

当过大时，则会导致后面部分权重比加大，那么最终损失函数过大，从而导致欠拟合。

当过小时，甚至为0，导致过拟合。

![img](https://img-blog.csdn.net/20180607144122278)

2、对于神经网络，参数膨胀原因可能是因为随着网路深度的增加，同时参数也不断增加，并且增加速度、规模都很大。那么可以采取减少神经网络规模（深度）的方法。也可以用一种叫dropout的方法。dropout的思想是当一组参数经过某一层神经元的时候，去掉这一层上的一部分神经元，让参数只经过一部分神经元进行计算。注意这里的去掉并不是真正意义上的去除，只是让参数不经过一部分神经元计算而已。

![img](https://img-blog.csdn.net/20180607144135368)

以下摘抄自知乎-flyqq：

https://www.zhihu.com/question/59201590

过拟合（overfitting）是指在模型参数拟合过程中的问题，由于训练数据包含抽样误差，训练时，复杂的模型将抽样误差也考虑在内，将抽样误差也进行了很好的拟合。

具体表现就是最终模型在训练集上效果好；在测试集上效果差。模型泛化能力弱。

![img](https://img-blog.csdn.net/20180607144146406)

为什么要解决过拟合现象？这是因为我们拟合的模型一般是用来预测未知的结果（不在训练集内），过拟合虽然在训练集上效果好，但是在实际使用时（测试集）效果差。同时，在很多问题上，我们无法穷尽所有状态，不可能将所有情况都包含在训练集上。所以，必须要解决过拟合问题。

为什么在机器学习中比较常见？这是因为机器学习算法为了满足尽可能复杂的任务，其模型的拟合能力一般远远高于问题复杂度，也就是说，机器学习算法有「拟合出正确规则的前提下，进一步拟合噪声」的能力。

而传统的函数拟合问题（如机器人系统辨识），一般都是通过经验、物理、数学等推导出一个含参模型，模型复杂度确定了，只需要调整个别参数即可。模型「无多余能力」拟合噪声。

既然过拟合这么讨厌，我们应该怎么防止过拟合呢？

### 1、获取更多数据

这是解决过拟合最有效的方法，只要给足够多的数据，让模型「看见」尽可能多的「例外情况」，它就会不断修正自己，从而得到更好的结果：

如何获取更多数据，可以有以下几个方法：

1）从数据源头获取更多数据：这个是容易想到的，例如物体分类，我就再多拍几张照片好了；但是，在很多情况下，大幅增加数据本身就不容易；另外，我们不清楚获取多少数据才算够；

根据当前数据集估计数据分布参数，使用该分布产生更多数据：这个一般不用，因为估计分布参数的过程也会代入抽样误差。

2）数据增强（Data Augmentation）：通过一定规则扩充数据。如在物体分类问题里，物体在图像中的位置、姿态、尺度，整体图片明暗度等都不会影响分类结果。我们就可以通过图像平移、翻转、缩放、切割等手段将数据库成倍扩充；

![img](https://img-blog.csdn.net/20180607144218874)

### 2、使用合适的模型

前面说了，过拟合主要是有两个原因造成的：数据太少+模型太复杂。所以，我们可以通过使用合适复杂度的模型来防止过拟合问题，让其足够拟合真正的规则，同时又不至于拟合太多抽样误差。

对于神经网络而言，我们可以从以下四个方面来限制网络能力：

#### 2.1、网络结构 Architecture

这个很好理解，减少网络的层数、神经元个数等均可以限制网络的拟合能力；

![img](https://img-blog.csdn.net/20180607144237870)

#### 2.2、训练时间 Early stopping

对于每个神经元而言，其激活函数在不同区间的性能是不同的：

![img](https://img-blog.csdn.net/20180607144246420)

当网络权值较小时，神经元的激活函数工作在线性区，此时神经元的拟合能力较弱（类似线性神经元）。

有了上述共识之后，我们就可以解释为什么限制训练时间（early stopping）有用：因为我们在初始化网络的时候一般都是初始为较小的权值。训练时间越长，部分网络权值可能越大。如果我们在合适时间停止训练，就可以将网络的能力限制在一定范围内。

#### 2.3、限制权值 Weight-decay，也叫正则化（regularization）

原理同上，但是这类方法直接将权值的大小加入到 Cost 里，在训练的时候限制权值变大。以 L2 regularization为例：

![img](https://img-blog.csdn.net/20180607144319645) 

训练过程需要降低整体的Cost，这时候，一方面能降低实际输出与样本之间的误差 ，也能降低权值大小。

#### 2.4、增加噪声 Noise

给网络加噪声也有很多方法：

#### 2.4.1、在输入中加噪声：

噪声会随着网络传播，按照权值的平方放大，并传播到输出层，对误差 Cost 产生影响。推导直接看 Hinton 的 PPT 吧：

![img](https://img-blog.csdn.net/2018060714433333)

在输入中加高斯噪声，会在输出中生成 的干扰项。训练时，减小误差，同时也会对噪声产生的干扰项进行惩罚，达到减小权值的平方的目的，达到与 L2 regularization 类似的效果（对比公式）。

#### 2.4.2、在权值上加噪声

在初始化网络的时候，用0均值的高斯分布作为初始化。Alex Graves 的手写识别 RNN 就是用了这个方法

Graves,Alex, et al. "A novel connectionist system for unconstrained handwritingrecognition." IEEE transactions on pattern analysis and machineintelligence 31.5 (2009): 855-868.

- Itmay work better, especially in recurrent networks (Hinton)

#### 2.4.3、对网络的响应加噪声

如在前向传播过程中，让默写神经元的输出变为 binary 或 random。显然，这种有点乱来的做法会打乱网络的训练过程，让训练更慢，但据 Hinton 说，在测试集上效果会有显著提升 （But it doessignificantly better on the test set!）。

### 3、结合多种模型

简而言之，训练多个模型，以每个模型的平均输出作为结果。

从 N 个模型里随机选择一个作为输出的期望误差，会比所有模型的平均输出的误差 大（我不知道公式里的圆括号为什么显示不了）：

![img](https://img-blog.csdn.net/20180607144341252)

大概基于这个原理，就可以有很多方法了：

#### 3.1、Bagging

简单理解，就是分段函数的概念：用不同的模型拟合不同部分的训练集。以随机森林（Rand Forests）为例，就是训练了一堆互不关联的决策树。但由于训练神经网络本身就需要耗费较多自由，所以一般不单独使用神经网络做Bagging。

#### 3.2、Boosting

既然训练复杂神经网络比较慢，那我们就可以只使用简单的神经网络（层数、神经元数限制等）。通过训练一系列简单的神经网络，加权平均其输出。

![img](https://img-blog.csdn.net/20180607144347976)

#### 3.3、Dropout

这是一个很高效的方法。

![img](https://img-blog.csdn.net/20180607144358597)

在训练时，每次随机（如50%概率）忽略隐层的某些节点；这样，我们相当于随机从2^H个模型中采样选择模型；同时，由于每个网络只见过一个训练数据（每次都是随机的新网络），所以类似 bagging 的做法，这就是我为什么将它分类到「结合多种模型」中；

此外，而不同模型之间权值共享（共同使用这 H 个神经元的连接权值），相当于一种权值正则方法，实际效果比 L2regularization 更好。

#### 4、贝叶斯方法

这部分我还没有想好怎么才能讲得清楚，为了不误导初学者，我就先空着，以后如果想清楚了再更新。当然，这也是防止过拟合的一类重要方法。

![img](https://img-blog.csdn.net/20180607144407384)

知乎-李俊毅：

防止overfitting三个角度：
1）数据：augmentation；

2）网络：简单化网络；

3）plus：正则，dropout等网络模型的变种。

