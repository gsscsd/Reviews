### 泛化误差（error）

我们知道，算法在不同训练集上学得的结果很可能不同，即便这些训练集是来自于同一个分布。以回归任务为例，对测试样本x，令$y_D$为x在数据集上的标记，y为x的真实标记，由于噪声的存在，有可能$y_D≠y$，$f(x;D)$为在训练集D上学得函数f对x的预测输出。因此，算法的期望预测可以表示为 
$$\bar{f}(x)=\mathbb{E}_D[f(x;D)]$$
不同训练集学得的函数ff的预测输出的方差（variance）为 
$$var(x)=\mathbb{E}_D[(f(x;D)-\bar{f}(x))^2]$$

期望输出与真实标记之间的差距称为偏差（bias），即 

$${bias}^2(x)=(\bar{f}(x)-y)^2$$

噪声为

$$\varepsilon^2=\mathbb{E}_D[(y_D-y)^2]$$

为方便讨论，假定噪声期望为零，即$E_D[y_D−y]=0$。算法的期望泛化误差为
$$
\begin{eqnarray*}
E(f;D)
&=& \mathbb{E}_D[(f(x;D)-y_D)^2]\\
&=& \mathbb{E}_D[(f(x;D)-\bar{f}(x)+\bar{f}(x)-y_D)^2]\\
&=& \mathbb{E}_D[(f(x;D)-\bar{f}(x))^2]+\mathbb{E}_D[(\bar{f}(x)-y_D)^2]+\color{red}{\mathbb{E}_D[2(f(x;D)-\bar{f}(x))(\bar{f}(x)-y_D)]}\\
&=& \mathbb{E}_D[(f(x;D)-\bar{f}(x))^2]+\mathbb{E}_D[(\bar{f}(x)-y_D)^2]\\
&=& \mathbb{E}_D[(f(x;D)-\bar{f}(x))^2]+\mathbb{E}_D[(\bar{f}(x)-y+y-y_D)^2]\\
&=& \mathbb{E}_D[(f(x;D)-\bar{f}(x))^2]+\mathbb{E}_D[(\bar{f}(x)-y)^2]+\mathbb{E}_D[(y-y_D)^2]+\color{red}{\mathbb{E}_D[2(\bar{f}(x)-y)(y-y_D)]}\\
&=& \mathbb{E}_D[(f(x;D)-\bar{f}(x))^2]+(\bar{f}(x)-y)^2+\mathbb{E}_D[(y-y_D)^2]
\end{eqnarray*}
$$
式中，第一个加红公式等于0，因为$(f(x;D)-\bar{f}(x))$与$(\bar{f}(x)-y)$相互独立，所以$\mathbb{E}_D[2(f(x;D)-\bar{f}(x))(\bar{f}(x)-y_D)]=2\mathbb{E}_D[(f(x;D)-\bar{f}(x))]\mathbb{E}_D[\bar{f}(x)-y_D)]$，根据期望预测公式$\bar{f}(x)=\mathbb{E}_D[f(x;D)$有$\mathbb{E}_D[(f(x;D)-\bar{f}(x))]=0$。同理第二个加红公式等于0，因为噪声期望为0。于是
$$E(f;D)={bias}^2(x)+var(x)+\varepsilon^2$$
也就是说，泛化误差可分解为偏差、方差与噪声之和。噪声无法人为控制，所以通常我们认为
$$E(f;D)={bias}^2(x)+var(x)$$

偏差（bias）与方差（variance）
根据上面的定义，偏差（bias）反映了模型在样本上的期望输出与真实标记之间的差距，即模型本身的精准度，反映的是模型本身的拟合能力。方差（variance）反映了模型在不同训练数据集下学得的函数的输出与期望输出之间的误差，即模型的稳定性，反应的是模型的波动情况。下面用打靶的例子直观展示了偏差和方差。 

![è¿éåå¾çæè¿°](https://img-blog.csdn.net/20180610200157351?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hvaGFpeng=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

图中红色的靶心表示测试样本的真实标记，蓝色的点表示模型在不同训练集上选出的函数的输出。第一列的两个图中，蓝色的点都比较集中，说明模型的稳定性好，也就是方差小；第一行的两个图中，蓝色点的中心都比较靠近红色靶心，说明模型的拟合能力强，也就是偏差小。所以总结如下： 
low bias and low variance：又准又稳 
low bias and high variance： 准但不稳 
high bias and low variance：不准但稳 
high bias and high variance：不准又不稳 
那模型和偏差、方差之间的对应关系是什么样呢？还是以回归任务为例，看一个极端例子，y=cy=c，不论模型的训练数据如何变化，学得的函数都不会变，因此f(x;D)f(x;D)的输出都相同，即模型的稳定性非常好，但是对训练集的拟合也不是很好，显然对于测试样本的预测也不会很准确，这种对训练集刻画不足的情况，称为欠拟合（underfitting）。逐渐增加模型的复杂度，学得的函数对训练数据的拟合越来越好 

![è¿éåå¾çæè¿°](https://img-blog.csdn.net/20180610204416460?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hvaGFpeng=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

但是，对于一个复杂的模型，当我们稍微改变训练样本时，学得的函数差距将非常的大 

![è¿éåå¾çæè¿°](https://img-blog.csdn.net/20180610204619884?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hvaGFpeng=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

这说明复杂的模型对训练样本拟合很好，但是模型的波动性也很大，很可能在测试样本的表现非常差。可以理解为，复杂的模型将训练样本的特性当作全体样本的通性，将噪声引入了模型中，这种现象称之为过拟合（overfitting）。所以我们需要在模型复杂度之间权衡，使偏差和方差得以均衡（trade-off），这样模型的整体误差才会最小。 

![è¿éåå¾çæè¿°](https://img-blog.csdn.net/20180610205513473?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hvaGFpeng=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

### 欠拟合和过拟合应对策略

#### 欠拟合（刻画不够）

- 寻找更好的特征，提升对数据的刻画能力
- 增加特征数量
- 重新选择更加复杂的模型

#### 过拟合（刻画太细，泛化太差）

- 增加训练样本数量，样本多了，噪声比中就减少了
- 减少特征维数，高维空间密度小
- 加入正则化项，使得模型更加平滑

### 模型选择

同一模型在不同训练集上学得的函数往往不同，那我们怎样才能选出最好的模型和最好的函数呢？可以采用交叉验证（Cross Validation）法，其基本思路如下：将训练集划分为K份，每次采用其中K-1份作为训练集，另外一份作为验证集，在训练集上学得函数后，然后在验证集上计算误差。再次选择另外K-1份数据再次重复上述过程，最终模型的误差为学得的K个函数的误差的平均值，并依据此值选择最佳模型，最后在整个训练集上训练选择的最佳模型，并在测试集上进行测试。 

![è¿éåå¾çæè¿°](https://img-blog.csdn.net/20180610213405352?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hvaGFpeng=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

同时，交叉验证也解决了上面说的variance（不同训练集学得的函数的差异）和bias（不同函数的平均值）两大问题。说白了，交叉验证验证了你的模型是否够精确，够稳定，不能说在某个数据集上表现好就可以，你做的模型是要放在整个数据集上来看的，毕竟泛化能力才是机器学习的核心。